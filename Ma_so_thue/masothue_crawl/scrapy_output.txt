2022-04-09 18:12:35 [scrapy.utils.log] INFO: Scrapy 2.5.0 started (bot: masothue_crawl)
2022-04-09 18:12:35 [scrapy.utils.log] INFO: Versions: lxml 4.6.3.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.7.0, Python 3.6.9 (default, Mar 15 2022, 13:55:28) - [GCC 8.4.0], pyOpenSSL 20.0.1 (OpenSSL 1.1.1k  25 Mar 2021), cryptography 3.4.7, Platform Linux-5.4.0-81-generic-x86_64-with-Ubuntu-18.04-bionic
2022-04-09 18:12:35 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2022-04-09 18:12:35 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'masothue_crawl',
 'CONCURRENT_REQUESTS': 32,
 'CONCURRENT_REQUESTS_PER_DOMAIN': 16,
 'CONCURRENT_REQUESTS_PER_IP': 16,
 'COOKIES_ENABLED': False,
 'DOWNLOAD_DELAY': 2,
 'LOG_FILE': 'scrapy_output.txt',
 'LOG_STDOUT': True,
 'NEWSPIDER_MODULE': 'masothue_crawl.spiders',
 'SPIDER_MODULES': ['masothue_crawl.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 6.1; WOW64; Trident/7.0; rv:11.0) like '
               'Gecko'}
2022-04-09 18:12:36 [scrapy.extensions.telnet] INFO: Telnet Password: 7eb06f0b832db169
2022-04-09 18:12:36 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2022-04-09 18:12:36 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2022-04-09 18:12:36 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2022-04-09 18:12:36 [scrapy.middleware] INFO: Enabled item pipelines:
['masothue_crawl.pipelines.MasothueCrawlPipeline']
2022-04-09 18:12:36 [twisted] CRITICAL: Unhandled error in Deferred:
2022-04-09 18:12:36 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "/home/data/.local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1661, in _inlineCallbacks
    result = current_context.run(gen.send, result)
  File "/home/data/.local/lib/python3.6/site-packages/contextvars/__init__.py", line 38, in run
    return callable(*args, **kwargs)
  File "/home/data/.local/lib/python3.6/site-packages/scrapy/crawler.py", line 88, in crawl
    start_requests = iter(self.spider.start_requests())
  File "/home/data/Documents/Crawl_data/masothue_crawl/masothue_crawl/spiders/masothue_tablets.py", line 25, in start_requests
    mst_urls = pd.read_csv('./masothue_url.csv', names=['mst', 'url'])
  File "/home/data/.local/lib/python3.6/site-packages/pandas/io/parsers.py", line 688, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/data/.local/lib/python3.6/site-packages/pandas/io/parsers.py", line 454, in _read
    parser = TextFileReader(fp_or_buf, **kwds)
  File "/home/data/.local/lib/python3.6/site-packages/pandas/io/parsers.py", line 948, in __init__
    self._make_engine(self.engine)
  File "/home/data/.local/lib/python3.6/site-packages/pandas/io/parsers.py", line 1180, in _make_engine
    self._engine = CParserWrapper(self.f, **self.options)
  File "/home/data/.local/lib/python3.6/site-packages/pandas/io/parsers.py", line 2010, in __init__
    self._reader = parsers.TextReader(src, **kwds)
  File "pandas/_libs/parsers.pyx", line 382, in pandas._libs.parsers.TextReader.__cinit__
  File "pandas/_libs/parsers.pyx", line 674, in pandas._libs.parsers.TextReader._setup_parser_source
FileNotFoundError: [Errno 2] No such file or directory: './masothue_url.csv'
2022-05-26 22:05:59 [scrapy.utils.log] INFO: Scrapy 2.6.1 started (bot: masothue_crawl)
2022-05-26 22:05:59 [scrapy.utils.log] INFO: Versions: lxml 4.8.0.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.9.12 (main, Mar 24 2022, 16:21:12) - [GCC 7.5.0], pyOpenSSL 22.0.0 (OpenSSL 1.1.1n  15 Mar 2022), cryptography 36.0.2, Platform Linux-5.4.0-81-generic-x86_64-with-glibc2.27
2022-05-26 22:05:59 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'masothue_crawl',
 'LOG_FILE': 'scrapy_output.txt',
 'LOG_STDOUT': True,
 'NEWSPIDER_MODULE': 'masothue_crawl.spiders',
 'SPIDER_MODULES': ['masothue_crawl.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (compatible; MSIE 10.0; Windows NT 6.1; WOW64; '
               'Trident/6.0)'}
2022-05-26 22:05:59 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2022-05-26 22:05:59 [scrapy.extensions.telnet] INFO: Telnet Password: d710cc5f6978bd46
2022-05-26 22:05:59 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2022-05-26 22:05:59 [py.warnings] WARNING: /usr/lib/python3/dist-packages/requests/__init__.py:78: RequestsDependencyWarning: urllib3 (1.26.9) or chardet (3.0.4) doesn't match a supported version!
  warnings.warn("urllib3 ({0}) or chardet ({1}) doesn't match a supported "

2022-05-26 22:05:59 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2022-05-26 22:05:59 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2022-05-26 22:05:59 [scrapy.middleware] INFO: Enabled item pipelines:
['masothue_crawl.pipelines.MasothueCrawlPipeline']
2022-05-26 22:05:59 [twisted] CRITICAL: Unhandled error in Deferred:
2022-05-26 22:05:59 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "/home/data/.local/lib/python3.9/site-packages/twisted/internet/defer.py", line 1660, in _inlineCallbacks
    result = current_context.run(gen.send, result)
  File "/home/data/.local/lib/python3.9/site-packages/scrapy/crawler.py", line 103, in crawl
    start_requests = iter(self.spider.start_requests())
  File "/home/data/Documents/Crawl_data/masothue_crawl/masothue_crawl/spiders/masothue_tablets.py", line 25, in start_requests
    mst_urls = pd.read_csv('./masothue_url.csv', names=['mst', 'url'])
  File "/home/data/.local/lib/python3.9/site-packages/pandas/util/_decorators.py", line 311, in wrapper
    return func(*args, **kwargs)
  File "/home/data/.local/lib/python3.9/site-packages/pandas/io/parsers/readers.py", line 680, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/data/.local/lib/python3.9/site-packages/pandas/io/parsers/readers.py", line 575, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/data/.local/lib/python3.9/site-packages/pandas/io/parsers/readers.py", line 933, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/data/.local/lib/python3.9/site-packages/pandas/io/parsers/readers.py", line 1217, in _make_engine
    self.handles = get_handle(  # type: ignore[call-overload]
  File "/home/data/.local/lib/python3.9/site-packages/pandas/io/common.py", line 789, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: './masothue_url.csv'
